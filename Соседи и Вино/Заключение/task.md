Правда ли, что все вина одинаковые? Вина различаются оттенками вкуса и аромата, крепостью, и все эти характеристики можно измерить.

Алгоритм `k` ближайших соседей позволяет классифицировать вина, основываясь на их измеренных свойствах. Если создать больше классов и собрать дополнительные данные по их характеристикам, то можно, например, использовать алгоритм для того, чтобы аналитически определять, понравится ли вам то или иное вино, или нет (относится ли оно к классу вин, которые понравились вам ранее).

В данном уроке мы рассмотрели основы построения и настройки алгоритма, использующего метод `k` ближайших соседей. Продолжить изучение этого метода вы можете с помощью следующих ресурсов:
- [Статья на machinelearning.ru](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9) содержит некоторые дополнительные математические формулы.
- [Видео на канале Simplilearn (англ.)](https://www.youtube.com/watch?v=4HKqjENq9OU) описывает и комментирует процесс построения алгоритма.
- [Видео из курса "Введение в машинное обучение от ВШЭ"](https://www.coursera.org/lecture/vvedenie-mashinnoe-obuchenie/mietod-blizhaishikh-sosiediei-jCkvu) в числе прочего рассказывает о различных примерах использования алгоритма.

Алгоритм `k` ближайших соседей реализован в библиотеке [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Используя его, необходимо указывать ряд параметров (количество соседей `k`, вес каждого соседа, функцию расстояния и другие), информацию о которых вы найдете в описании алгоритма. Как правило, сложные параметры являются необязательными: им присваиваются значения по умолчанию.

Запуская алгоритм с различными `k`, можно наблюдать, как пропорционально этому параметру растет и время работы. Дело в том, что [сложность алгоритма](https://ru.wikipedia.org/wiki/%D0%92%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B0) линейно зависит от `k` (при условии, что наш набор данных хорошо разбивается на кластеры). Существуют и более быстрые версии алгоритма, ознакомиться с их списком вы можете здесь [англ.](https://en.wikipedia.org/wiki/K-means_clustering#Variations).

> <i>Этот курс сейчас в альфа-версии. Пожалуйста, помогите нам его улучшить. Для этого вы можете ответить
> на вопросы к каждому из заданий данного урока в опроснике по <a href="https://docs.google.com/forms/d/e/1FAIpQLSfix9bjakXkVGr7c0ErZWzzIdGUUAGwASokBj8CB0ql0s5HWA/viewform?usp=sf_link">ссылке</a>.
> Cпасибо :) </i>