Наивный байесовский алгоритм&nbsp;— один из наиболеее часто используемых при обработке 
естественных языков: при решении таких задач, он превосходит многие другие алгоритмы. 
Благодаря этому, НБА находит широкое применение в области фильтрации спама 
(идентификация спама в электронных письмах) и анализа тональности текста (анализ 
социальных медиа, идентификация позитивных и негативных мнений клиентов). Однако у 
него есть и другие области применения. 

- Наивный байесовский алгоритм очень быстро обучается, вследствие чего его можно 
  использовать для **классификации данных в режиме реального времени**.
  
- Наивный байесовский классификатор в сочетании с коллаборативной фильтрацией 
  (collaborative filtering) позволяет реализовать **рекомендательную систему**, 
  в рамках которой новая для пользователя информация отфильтровывается на основании 
  спрогнозированного мнения этого пользователя о ней при помощи методов машинного 
  обучения и интеллектуального анализа данных. Подобные системы широко используются такими сервисами,
  как Netflix, Amazon, Facebook и Google.
  
- НБА позволяет прогнозировать вероятности для множества значений целевой переменной, 
  то есть обеспечивает возможность **многоклассовой классификации**.
  
- [Байесовский подход в филогенетике](https://ru.wikipedia.org/wiki/%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D0%BE%D0%B4%D1%85%D0%BE%D0%B4_%D0%B2_%D1%84%D0%B8%D0%BB%D0%BE%D0%B3%D0%B5%D0%BD%D0%B5%D1%82%D0%B8%D0%BA%D0%B5) позволяет получить наиболее вероятные 
  филогенетические деревья при заданных исходных данных&nbsp;— последовательностях 
  ДНК или белков рассматриваемых организмов и эволюционной модели замен нуклеотидов. 
  Преимущества в скорости вычислений и возможность интеграции с методами [MCMC](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D1%86%D0%B5%D0%BF%D1%8C_%D0%9C%D0%BE%D0%BD%D1%82%D0%B5-%D0%9A%D0%B0%D1%80%D0%BB%D0%BE) 
  (Markov chain Monte Carlo) позволили байесовскому подходу стать одним из самых 
  популярных методов статистического вывода. Развитие методов MCMC позволяет вычислять 
  большие иерархические модели, требующие интеграции от сотен до тысяч неизвестных 
  параметров.

### Плюсы и минусы НБА

**Плюсы**:
- Классификация, в том числе многоклассовая, выполняется легко и быстро.
- Хорошо работает с категориальными признаками.
- Когда допущение о независимости выполняется, наивный байесовский классификатор 
  работает лучше, чем другие алгоритмы, такие как, например, логистическая регрессия 
  (logistic regression), и при этом требует меньший объем данных для обучения.

**Минусы**:
- Ограничением является допущение о независимости признаков. В реальности 
  наборы полностью независимых признаков встречаются крайне редко.
- Существует проблема “нулевой частоты”, но она решается с помощью сглаживания.
- Данный алгоритм работает с непрерывными признаками хуже, чем с категориальными. 
  Для непрерывных предполагается нормальное распределение, что является сильным допущением.
  
При решении реальных задач, требующих использования Байесовского метода, удобно не писать весь код с нуля, a пользоваться, к примеру,
модулем [sklearn.naive_bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) библиотеки scikit-learn, где уже имплементированы нужные алгоритмы. 
Это библиотека с открытым исходным кодом, предоставляющая широкий выбор алгоритмов обучения.


> <i>Этот курс сейчас в альфа-версии. Пожалуйста, помогите нам его улучшить. Для этого вы можете ответить
> на вопросы к каждому из заданий данного урока в опроснике по <a href="https://docs.google.com/forms/d/e/1FAIpQLSd3V5XUAMjCyU4uOuri9WKBEXpVsRfzCfMfVtnS8AzjqdXqFw/viewform?usp=sf_link">ссылке</a>.
> Cпасибо :) </i>
