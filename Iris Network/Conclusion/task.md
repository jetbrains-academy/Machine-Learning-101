Neural networks are used in numerous tasks – as a rule, quite difficult tasks, like, for example, image recognition.
In human brain, such processes are unconscious and their algorithms are unknown or little known. As a matter of fact, neural networks
have been designed specifically to help with solving problems with unknown or little known algorithms.
Neural networks are not programmed in the habitual sense of the word – they are trained.
The possibility of training is one of the major advantages of neural networks compared to conventional algorithms.


Despite the fact that backpropagation was invented quite long ago, neural networks did not enjoy popularity till the mid-2000s.
The reason is, there were no sufficient computing capacities (including those with graphic accelerators, programmable gate arrays, and various kinds of neural processors) and data volumes. Besides, there was no
opportunity to quickly test new architectures specifically tailored for certain tasks.

One of the architectures that triggered the growth of interest to neural networks is the  <a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D1%91%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C">convolutional neural network</a> 
(**CNN**). This is a type of Feedforward neural networks, 
i.e., such networks that do not have cycles or feedback loops. CNN are one of the best algorithms for image recognition
and classification.

Another interesting network architecture is the <a href="https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C">Recurrent NN</a> 
(**RNN**). These NN have feedback connections, i.e., connections from logically remote elements to less remote ones. Feedback connections allow remembering and reproducing
sequences of reaction to one stimulus, processing temporal event series or consecutive spatial chains.
RNN may be used in tasks where some entirety is broken into parts, for example,
handwritten text recognition or speech recognition. Besides, RNN may be used to generate
text or, for example, code.


<h3>Additional sources</h3>
- [scikit-learn](https://scikit-learn.org/stable/index.html) library &mdash; a popular resource for classical machine learning. It's an opensource library that
  offers a wide variety of [supervised](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#neural-networks-supervised)
  and [unsupervised](https://scikit-learn.org/stable/modules/neural_networks_unsupervised.html#neural-networks-unsupervised) learning algorithms. It contains
  realisations of practically all possible transformations; in many cases, it alone will be enough for a complete realisation of a model.
- “<a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a>” book.
- “<a href="https://books.google.ru/books/about/Neural_Networks.html?id=bX4pAQAAMAAJ&source=kp_book_description&redir_esc=y">Neural Networks: A Comprehensive Foundation</a>” book
  (also available in <a href="https://books.google.ru/books?id=LPMr0iA0muwC&printsec=copyright&hl=ru&source=gbs_pub_info_r#v=onepage&q&f=false">Russian translation</a>). 

> <i>This course is currently in the Alpha version. You can help us improve it by answering questions after each task in the following
> <a href="https://docs.google.com/forms/d/e/1FAIpQLSc7uQK8wSbhRUnReXtUeMKE0eRy6JjlutTH7iEbKzwKL1VV5g/viewform?usp=sf_link">form</a>.
> Thanks! :) </i>