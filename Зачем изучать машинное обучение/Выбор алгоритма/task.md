Задачи машинного обучения сводятся к нескольким типам:

### [Обучение с учителем (supervised learning)](http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC)
В таких задачах имеется множество объектов (стимулов) и ответов на них (реакций). К примеру, ответом может быть принадлежность объекта к некоторому классу объектов. Однако зависимость между стимулами и реакциями неизвестна. Для ее определения на основе эмпирических данных ([прецедентов](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%BD%D0%B0_%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D0%B0%D1%85) – стимулов, для которых известна реакция) обучается алгоритм, способный выдать для любого объекта достаточно точный ответ.

Совокупность заранее известных прецедентов, используемая для тренировки алгоритма, называется [обучающей выборкой](http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B0%D1%8E%D1%89%D0%B0%D1%8F_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B0).

#### [Классификация (classification)](http://www.machinelearning.ru/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F)
В задачах данного типа имеется множество объектов (ситуаций), разделенных некоторым образом на классы. В качестве обучающей выборки служит конечное множество объектов, для которых известны их классы. Примером такой задачи может служить медицинская диагностика, когда на основании наличия формально описанных медицинских анализов пациента можно выдвинуть предположение о наличии у него определенного заболевания.

Примеры решения подобной задачи рассматриваются в уроках **Neighbors and Wine**, **Horror Trees**, **Pima indians diabetes and linear classifier**, а также **Iris Network**.

#### [Регрессия (regression)](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F)
В данной задаче строится модель измеряемых данных и исследования их свойств. Данные состоят из пар значений зависимой переменной и независимой переменной. Результатом решения задачи будет являться модель, объясняющая зависимость переменной отклика от объясняющей. Примером такого анализа может являться модель, прогнозирующая зависимость цен на недвижимость от времени.

#### [Ранжирование (learning to rank)](http://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B0%D0%BD%D0%B6%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5)
При ранжировании необходимо отсортировать реакции, полученные для множества объектов, по их значениям. Решение может свестись к решению задачи классификации или регрессии. Задачи ранжирования можно встретить в информационном поиске и анализе текстов.

#### Структурное обучение
Собирательный термин для техник машинного обучения с учителем, которые подразумевают прогнозирование сложных структурных объектов, а не скалярных дискретных или вещественных значений. Пример такой задачи — дерево синтаксического разбора при обработке естественного языка.

### [Обучение без учителя (unsupervised learning)](http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B1%D0%B5%D0%B7_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F)
В данном классе задач известно только описание множества объектов (обучающая выборка), и на основании этого необходимо обнаружить зависимости, существующие между объектами.

#### [Кластеризация](http://www.machinelearning.ru/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F)
Задача заключается в том, чтобы сгруппировать объекты в кластеры, используя данные о попарном сходстве объектов.
Пример решения подобной задачи рассматривается в уроке **Comic-Con and k-means**.

#### Поиск ассоциативных правил
Исходные данные представляются в виде признаковых описаний. Требуется найти такие наборы признаков и такие значения этих признаков, которые особенно часто (неслучайно часто) встречаются в признаковых описаниях объектов.

### [Частичное обучение (semi-supervised learning)](http://www.machinelearning.ru/wiki/index.php?title=%D0%A7%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)
Занимает промежуточное положение между обучением с учителем и без учителя. В таких задачах используются и размеченные, и неразмеченные данные. Такая ситуация возможна, если в обучающей выборке ответы известны только для части прецедентов. Пример прикладной задачи такого типа — автоматическая рубрикация большого количества текстов при условии, что некоторые из них уже отнесены к каким-то рубрикам.

Пример решения подобной задачи рассмотрен в уроке **Bayes guards SMS**.

### Активное обучение (active learning, [eng](https://en.wikipedia.org/wiki/Active_learning_(machine_learning)))
Отличается тем, что обучаемый алгоритм имеет возможность самостоятельно назначать следующую исследуемую ситуацию, для которой станет известен верный ответ: например, объект с заранее указанным классом. Такой подход может встретиться в тех случаях, когда существует достаточное количество данных, но ручное определение класса для каждого из объектов требует больших усилий. Одним из примеров использования алгоритмов активного обучения может послужить анализ различных изображений в астрономии – разметка объектов на поверхностях планет, классификация звезд, галактик и т.п. – когда сами изображения получены в больших количествах, но определять на них объекты требуется вручную, используя дорогостоящий труд профессионалов.


> <i>Этот курс сейчас в альфа-версии. Пожалуйста, помогите нам его улучшить. Для этого вы можете ответить
> на вопросы к каждому из заданий данного урока в опроснике по <a href="https://docs.google.com/forms/d/e/1FAIpQLSetRXApA3fyEOLne7Ag5lkYrP7nuXfVP_M8bUNJGcDEQjP9kg/viewform?usp=sf_link">ссылке</a>.
> Cпасибо :) </i>